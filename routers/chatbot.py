# routers/chatbot.py
from fastapi import APIRouter, Depends, Request, Response, Query
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
from uuid import uuid4
from datetime import datetime, timedelta
import os, time, json, re, requests

from sqlalchemy.orm import Session
from sqlalchemy import text
from sqlalchemy.exc import ProgrammingError
from core.db import get_db

from services.rag_index import search_products, build_index_from_db, index_meta
from openai import OpenAI

router = APIRouter(prefix="/chatbot", tags=["chatbot"])

# ----- í™˜ê²½ -----
ENV = os.getenv("ENV", "dev").lower()          # dev | prod
COOKIE_NAME = "session_id"
SESSION_TTL_HOURS = int(os.getenv("SESSION_TTL_HOURS", "24"))
ANALYTICS_BASE = os.getenv("ANALYTICS_BASE", "http://127.0.0.1:8000")
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ----- ìŠ¤í‚¤ë§ˆ -----
class ChatIn(BaseModel):
    message: str

class Recommendation(BaseModel):
    product_id: Optional[str] = None
    name: Optional[str] = None
    price: Optional[float] = None
    link: Optional[str] = None
    score: Optional[float] = None
    rating: Optional[float] = None
    evidence: Optional[List[Dict[str, Any]]] = None

class ChatOut(BaseModel):
    answer: str
    recommendations: Optional[List[Recommendation]] = None
    used_contexts: Optional[List[Dict[str, Any]]] = None
    session_id: Optional[str] = None
    meta: Optional[Dict[str, Any]] = None

# ----- ì¿ í‚¤/ì„¸ì…˜ -----
def _set_session_cookie(response: Response, sid: str):
    secure = (ENV == "prod")
    samesite = "none" if secure else "lax"
    response.set_cookie(
        key=COOKIE_NAME,
        value=sid,
        httponly=True,
        secure=secure,
        samesite=samesite,
        max_age=SESSION_TTL_HOURS * 3600,
    )

def _ensure_session(request: Request, response: Response, db: Session) -> str:
    sid = request.cookies.get(COOKIE_NAME)
    now = datetime.utcnow()
    exp = now + timedelta(hours=SESSION_TTL_HOURS)

    # ê³µí†µ UPSERT SQL (í–‰ì´ ì—†ì–´ë„ ë„£ê³ , ìˆìœ¼ë©´ ê°±ì‹ )
    upsert_sql = text("""
        INSERT INTO sessions (id, started_at, last_active, expires_at)
        VALUES (:id, NOW(), NOW(), :exp)
        ON CONFLICT (id) DO UPDATE
            SET last_active = EXCLUDED.last_active,
                expires_at  = EXCLUDED.expires_at;
    """)

    try:
        if not sid:
            sid = str(uuid4())
            _set_session_cookie(response, sid)
        db.execute(upsert_sql, {"id": sid, "exp": exp})
        db.commit()
        return sid
    except ProgrammingError as e:
        # í…Œì´ë¸”ì´ ì—†ì–´ì„œ ì‹¤íŒ¨í•œ ê²½ìš° â€“ ë°©ì–´ì ìœ¼ë¡œ í…Œì´ë¸” ë§Œë“¤ê³  ì¬ì‹œë„
        ensure_chatbot_tables()
        db.execute(upsert_sql, {"id": sid, "exp": exp})
        db.commit()
        return sid

def _load_recent_context(db: Session, session_id: str, limit_turns: int = 6) -> List[Dict[str, Any]]:
    rows = db.execute(text("""
      SELECT role, content
      FROM messages
      WHERE session_id=:sid
      ORDER BY created_at DESC
      LIMIT :lim
    """), {"sid": session_id, "lim": limit_turns}).fetchall()
    return [{"role": r[0], "content": r[1]} for r in rows[::-1]]

def _save_message(db, session_id, role, content, meta=None):
    stmt = text("""
        INSERT INTO messages (session_id, role, content, meta)
        VALUES (:sid, :role, :content, CAST(:meta AS JSONB))
    """)
    db.execute(
        stmt,
        {
            "sid": str(session_id),
            "role": role,
            "content": content,
            "meta": json.dumps(meta or {}, ensure_ascii=False),
        },
    )
    db.commit()

# ----- ë¼ìš°íŒ…/LLM & ìŠ¤ëª°í†¡ -----
def _route_kind(q: str) -> str:
    if any(k in q.lower() for k in ["top", "count", "trend", "distribution", "average"]):
        return "analytics"
    if any(k in q for k in ["íƒ‘", "ìˆœìœ„", "ë§ì´", "í‰ê· ", "ë¶„í¬", "ì›”ë³„", "ì¶”ì´", "ê°œìˆ˜", "ë¹„ìœ¨"]):
        return "analytics"
    return "rag"

_HELLOS = ["ì•ˆë…•", "ì•ˆë‡½", "í•˜ì´", "hello", "hi"]
_THANKS = ["ê³ ë§ˆì›Œ", "ê°ì‚¬", "thanks", "thank you", "ë•¡í"]
_INTENT_HINTS = [
    "ì¶”ì²œ", "ìì¼“", "ì¬í‚·", "ìƒì˜", "í•˜ì˜", "ë°”ì§€", "íŒ¨ë”©", "ì í¼", "ë² ìŠ¤íŠ¸",
    "í‹°ì…”ì¸ ", "ì…”ì¸ ", "ëŸ¬ë‹í™”", "ì‹ ë°œ", "ë“±ì‚°í™”", "ê°€ë°©", "ê°€ê²©", "ì˜ˆì‚°", "ë§í¬"
]
def _is_smalltalk(q: str) -> Optional[str]:
    low = (q or "").strip().lower()
    if any(h in low for h in [w.lower() for w in _INTENT_HINTS]):
        return None
    if any(w in low for w in [h.lower() for h in _HELLOS]):
        return "hello"
    if any(w in low for w in [t.lower() for t in _THANKS]):
        return "thanks"
    return None

def _is_non_product(q: str) -> bool:
    """ë‚ ì”¨/ì¼ìƒ/ë¹„ìƒí’ˆ ëŒ€í™”ëŠ” ì—¬ê¸°ì„œ ì»·."""
    low = (q or "").lower()
    return any(k in low for k in ["ë‚ ì”¨", "ê¸°ì˜¨", "ì‹œê°„", "ë‰´ìŠ¤", "ì£¼ê°€", "êµí†µ", "ìš”ë¦¬ ë ˆì‹œí”¼"])

def _call_llm(system_prompt: str, messages: List[Dict[str, str]]) -> str:
    comp = client.chat.completions.create(
        model=OPENAI_MODEL,
        messages=[{"role": "system", "content": system_prompt}] + messages,
        temperature=0.3,
        max_tokens=350,
    )
    return comp.choices[0].message.content.strip()

SYSTEM_PROMPT = (
    "ë‹¹ì‹ ì€ ë°ì¹´íŠ¸ë¡  ìƒí’ˆ ë¦¬ë·° ê¸°ë°˜ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. "
    "í•­ìƒ ë¦¬ë·°/ìš”ì•½ì—ì„œ ì°¾ì€ ê·¼ê±°ë¡œë§Œ ë‹µí•˜ê³ , í™•ì‹¤í•˜ì§€ ì•Šìœ¼ë©´ ê·¼ê±° ë¶€ì¡±ì„ ì•Œë¦¬ì„¸ìš”. "
    "ì¶”ì²œì€ ì œí’ˆëª…/ëŒ€ëµ ê°€ê²©/í•µì‹¬ ì¥ì  1-2ê°œë¥¼ ê°„ë‹¨íˆ ì œì‹œí•˜ì„¸ìš”. "
    "ì¶œë ¥ì€ ê°„ë‹¨í•œ ë¬¸ì¥ 2-5ê°œì™€ ê·¼ê±° ìŠ¤ë‹ˆí« 1-3ê°œë¥¼ í¬í•¨í•˜ì„¸ìš”."
)

# ----- ë¶„ì„ API ë§¤í•‘ -----
def _analytics_dispatch(text_query: str) -> Dict[str, Any]:
    mapping = [
        (["ëŸ¬ë‹", "í‰ì ", "íƒ‘", "top"], "/running/top-rated"),
        (["ëŸ¬ë‹", "ë¦¬ë·°", "ë§ì´", "top"], "/running/top-by-reviewcount"),
        (["í•˜ì´í‚¹", "í‰ì ", "íƒ‘", "top"], "/hiking/top-rated"),
        (["í•˜ì´í‚¹", "ë¦¬ë·°", "ë§ì´", "top"], "/hiking/top-by-reviewcount"),
        (["ì›”ë³„", "ì¶”ì´"], "/total/monthly-reviews"),
        (["ê°€ê²©", "ë¶„í¬", "ì „ì²´"], "/total/price-bins"),
        (["ëŸ¬ë‹", "ê°€ê²©", "ë¶„í¬"], "/running/price-distribution"),
        (["í•˜ì´í‚¹", "ê°€ê²©", "ë¶„í¬"], "/hiking/price-distribution"),
        (["ì›Œë“œí´ë¼ìš°ë“œ", "ëŸ¬ë‹"], "/running/wordcloud"),
        (["ì›Œë“œí´ë¼ìš°ë“œ", "í•˜ì´í‚¹"], "/hiking/wordcloud"),
    ]
    q = text_query.lower()
    for keys, path in mapping:
        if all(k.lower() in q for k in keys):
            url = f"{ANALYTICS_BASE}{path}"
            try:
                r = requests.get(url, timeout=5)
                if r.ok:
                    return {"endpoint": path, "data": r.json()}
            except Exception as e:
                return {"endpoint": path, "error": str(e)}
    try:
        r = requests.get(f"{ANALYTICS_BASE}/total/top-by-reviewcount", timeout=5)
        if r.ok:
            return {"endpoint": "/total/top-by-reviewcount", "data": r.json()}
    except Exception as e:
        return {"endpoint": "/total/top-by-reviewcount", "error": str(e)}
    return {"endpoint": None, "error": "analytics not available"}

# ----- í›„ì† ì§ˆì˜/ì œì–´ ì‹ í˜¸ íŒŒì„œ -----
def _control_from_text(q: str) -> Dict[str, Any]:
    low = (q or "").lower()
    ctrl: Dict[str, Any] = {}

    # ë” ì €ë ´/ë¹„ì‹¼
    if any(k in low for k in ["ë” ì‹¸", "ì €ë ´", "ì‹¸ì§„", "ë‚®ì€ ê°€ê²©"]):
        ctrl["price_bias"] = "cheaper"
    if any(k in low for k in ["ë” ë¹„ì‹¸", "ê³ ê¸‰", "í”„ë¦¬ë¯¸ì—„", "ë¹„ì‹¼"]):
        ctrl["price_bias"] = "pricier"

    # ë¹„ìŠ·í•œ
    if any(k in low for k in ["ë¹„ìŠ·í•œ", "ìœ ì‚¬í•œ", "ê°™ì€ ë¼ì¸", "ê°™ì€ ì¢…ë¥˜"]):
        ctrl["prefer_similar"] = True

    # ì¸ê¸°(ë¦¬ë·°ìˆ˜)
    if any(k in low for k in ["ì¸ê¸°", "ë¦¬ë·° ë§", "ë² ìŠ¤íŠ¸", "íŒë§¤ëŸ‰"]):
        ctrl["prefer"] = "popular"

    # ê°€ì„±ë¹„
    if "ê°€ì„±ë¹„" in low:
        ctrl["prefer"] = "value"

    # Oë§Œì›ëŒ€ / ì´í•˜ / ì´ìƒ
    m = re.search(r"(\d+)\s*ë§Œ\s*ì›\s*ëŒ€", low)
    if m:
        n = int(m.group(1)) * 10000
        ctrl["min_price"] = n
        ctrl["max_price"] = n + 9999
    m = re.search(r"(\d+)\s*ë§Œ\s*ì›\s*(ì´í•˜|ë°‘|ê¹Œì§€)", low)
    if m:
        ctrl["max_price"] = int(m.group(1)) * 10000
    m = re.search(r"(\d+)\s*ë§Œ\s*ì›\s*(ì´ìƒ|ë¶€í„°)", low)
    if m:
        ctrl["min_price"] = int(m.group(1)) * 10000

    # â€œë‹¤ë¥¸ ì œí’ˆâ€ â†’ ì²« ê²°ê³¼ëŠ” ê±´ë„ˆë›°ê¸°
    if any(k in low for k in ["ë‹¤ë¥¸ ì œí’ˆ", "ë‹¤ë¥¸ ê±°", "ë˜ ë‹¤ë¥¸", "í•˜ë‚˜ ë”", "ë‹¤ë¥¸ê±°"]):
        ctrl["offset"] = 1

    # â€œNê°œâ€ ìš”ì²­
    m = re.search(r"(\d+)\s*ê°œ", low)
    if m:
        ctrl["top_k"] = max(1, min(5, int(m.group(1))))

    return ctrl

# ---------- Routes ----------
@router.get("/health")
def health():
    try:
        meta = index_meta()
    except Exception as e:
        meta = {"error": str(e)}
    return {"ok": True, "index": meta, "env": ENV}

@router.post("/reindex")
def reindex(db: Session = Depends(get_db)):
    info = build_index_from_db(db)
    return {"ok": True, "index": info}

@router.post("/chat", response_model=ChatOut)
def chat(
    req: ChatIn,
    request: Request,
    response: Response,
    db: Session = Depends(get_db),
    debug: bool = Query(False),
):
    t0 = time.time()
    session_id = _ensure_session(request, response, db)
    history = _load_recent_context(db, session_id, limit_turns=6)

    # ë¹„ìƒí’ˆ/ìŠ¤ëª°í†¡ ê°€ë“œ
    if _is_non_product(req.message):
        answer = "ì£„ì†¡í•´ìš”, ì €ëŠ” ì œí’ˆ ê´€ë ¨ ì§ˆë¬¸ì—ë§Œ ë‹µí•  ìˆ˜ ìˆì–´ìš”. ì›í•˜ì‹œëŠ” í’ˆëª©(ì˜ˆ: ë°©ìˆ˜ ìì¼“)ì´ë‚˜ ì˜ˆì‚°ì„ ì•Œë ¤ì£¼ì‹œë©´ ë°”ë¡œ ì¶”ì²œí•´ë“œë¦´ê²Œìš”."
        _save_message(db, session_id, "user", req.message, meta={"route": "non-product"})
        _save_message(db, session_id, "assistant", answer, meta={"route": "non-product"})
        latency_ms = int((time.time() - t0) * 1000)
        return ChatOut(answer=answer, recommendations=None, used_contexts=None,
                       session_id=session_id, meta={"latency_ms": latency_ms, "route": "non-product", "env": ENV})

    st = _is_smalltalk(req.message)
    if st == "hello":
        answer = "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”? ìì¼“/ë°”ì§€/ëŸ¬ë‹í™”ì²˜ëŸ¼ ì›í•˜ëŠ” í’ˆëª©ì´ë‚˜ ì˜ˆì‚°ì„ ë§í•´ì£¼ì‹œë©´ ë°”ë¡œ ì°¾ì•„ë“œë¦´ê²Œìš”."
        _save_message(db, session_id, "user", req.message, meta={"route": "smalltalk"})
        _save_message(db, session_id, "assistant", answer, meta={"route": "smalltalk"})
        latency_ms = int((time.time() - t0) * 1000)
        return ChatOut(answer=answer, recommendations=None, used_contexts=None,
                       session_id=session_id, meta={"latency_ms": latency_ms, "route": "smalltalk", "env": ENV})
    if st == "thanks":
        answer = "ë„ì›€ì´ ë˜ì–´ ê¸°ë»ìš”! ë” í•„ìš”í•œ ê²Œ ìˆìœ¼ë©´ ì–¸ì œë“  í¸í•˜ê²Œ ë¬¼ì–´ë³´ì„¸ìš” ğŸ™‚"
        _save_message(db, session_id, "user", req.message, meta={"route": "smalltalk"})
        _save_message(db, session_id, "assistant", answer, meta={"route": "smalltalk"})
        latency_ms = int((time.time() - t0) * 1000)
        return ChatOut(answer=answer, recommendations=None, used_contexts=None,
                       session_id=session_id, meta={"latency_ms": latency_ms, "route": "smalltalk", "env": ENV})

    # ë¶„ì„ ë¼ìš°íŒ…
    route = _route_kind(req.message)
    recs: List[Dict[str, Any]] = []
    used_contexts: Optional[List[Dict[str, Any]]] = None

    if route == "analytics":
        a = _analytics_dispatch(req.message)
        if "data" in a:
            data_preview = str(a["data"])[:300]
            answer = f"ë¶„ì„í˜• ì§ˆì˜ë¡œ íŒë‹¨ë˜ì–´ `{a['endpoint']}` ê²°ê³¼ë¥¼ ìš”ì•½í–ˆìŠµë‹ˆë‹¤.\nìš”ì•½ ë¯¸ë¦¬ë³´ê¸°: {data_preview}"
        else:
            answer = f"ë¶„ì„ API í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. endpoint={a.get('endpoint')}, error={a.get('error')}"
    else:
        # ---- ì œí’ˆ ì¶”ì²œ ----
        ctrl = _control_from_text(req.message)
        top_k = ctrl.get("top_k", 1)

        try:
            recs = search_products(
                req.message,
                top_k=top_k,
                offset=ctrl.get("offset", 0),
                min_price=ctrl.get("min_price"),
                max_price=ctrl.get("max_price"),
                price_bias=ctrl.get("price_bias"),        # 'cheaper' | 'pricier' | None
                prefer=ctrl.get("prefer"),                # 'popular' | 'value' | None
                prefer_similar=ctrl.get("prefer_similar", False),
            )
        except Exception:
            recs = []

        if debug:
            used_contexts = recs

        if recs:
            top = recs[0]
            prompt = (
                f"ì‚¬ìš©ì ì§ˆë¬¸: {req.message}\n\n"
                f"ì¶”ì²œ í›„ë³´(1ê°œ):\n"
                f"- ì´ë¦„: {top.get('name')}\n- ê°€ê²©: {top.get('price')}\n"
                f"- ì¹´í…Œê³ ë¦¬: {top.get('category')}/{top.get('subcategory')}\n"
                f"- ë§í¬: {top.get('link')}\n"
                f"- ê·¼ê±° ìŠ¤ë‹ˆí«: \"{top.get('snippet','')}\"\n"
                f"- í‰ê·  í‰ì : {top.get('rating')}\n\n"
                f"ìš”êµ¬ì‚¬í•­: 2~4ë¬¸ì¥ìœ¼ë¡œ ì§§ê²Œ ì¶”ì²œ ì‚¬ìœ ë¥¼ ì„¤ëª…í•˜ê³ , ì œí’ˆëª…/ê°€ê²©/í•µì‹¬ ì¥ì  1-2ê°œ/ë§í¬ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨í•˜ë¼."
            )
            llm_messages = [{"role": "user", "content": prompt}]
            for h in history[-4:]:
                llm_messages.insert(0, {"role": h["role"], "content": h["content"]})
            answer = _call_llm(SYSTEM_PROMPT, llm_messages)
        else:
            answer = "ìš”ì²­ê³¼ ë§ëŠ” ì œí’ˆì„ ì°¾ê¸° ì–´ë µë„¤ìš”. ì¹´í…Œê³ ë¦¬(ì˜ˆ: ìì¼“/í•˜ì˜/ì‹ ë°œ)ë‚˜ ì˜ˆì‚°ì„ ì¡°ê¸ˆ ë” ì•Œë ¤ì¤„ë˜ìš”?"

        for r in recs:
            r["evidence"] = [{
                "snippet": r.get("snippet"),
                "rating": r.get("rating"),
                "source": r.get("source", "reviews")
            }]

    _save_message(db, session_id, "user", req.message, meta={"route": route})
    _save_message(db, session_id, "assistant", answer, meta={"route": route})

    latency_ms = int((time.time() - t0) * 1000)
    return ChatOut(
        answer=answer,
        recommendations=recs or None,
        used_contexts=used_contexts,
        session_id=session_id,
        meta={"latency_ms": latency_ms, "route": route, "env": ENV},
    )